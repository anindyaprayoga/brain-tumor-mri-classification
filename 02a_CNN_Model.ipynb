{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Brain Tumor MRI Classification Project"
      ],
      "metadata": {
        "id": "mL4j8GugDI8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Project Overview"
      ],
      "metadata": {
        "id": "iciabp01DNeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Preprocessed Data"
      ],
      "metadata": {
        "id": "8aFP2p1aKOyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "def extract_preprocessed_data():\n",
        "    zip_candidates = ['/content/preprocessed_data.zip', *glob.glob('/content/*preprocessed*.zip')]\n",
        "    zip_path = None\n",
        "    for candidate in zip_candidates:\n",
        "        if os.path.exists(candidate):\n",
        "            zip_path = candidate\n",
        "            break\n",
        "\n",
        "    if not zip_path:\n",
        "        print(\"preprocessed_data.zip not found in /content/\")\n",
        "        return False\n",
        "\n",
        "    if os.path.exists('/content/preprocessed_data') and os.path.exists('/content/preprocessed_data/config.json'):\n",
        "        required_files = [\n",
        "            'X_train.npy', 'X_val.npy', 'X_test.npy',\n",
        "            'y_train.npy', 'y_val.npy', 'y_test.npy',\n",
        "            'y_train_cat.npy', 'y_val_cat.npy', 'y_test_cat.npy',\n",
        "            'config.json'\n",
        "        ]\n",
        "        missing = [f for f in required_files if not os.path.exists(f'/content/preprocessed_data/{f}')]\n",
        "        if not missing:\n",
        "            print(\"preprocessed_data folder already exists\")\n",
        "            return True\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/')\n",
        "\n",
        "        print(f\"Extraction completed: {os.path.basename(zip_path)}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "if extract_preprocessed_data():\n",
        "    for f in sorted(os.listdir('/content/preprocessed_data')):\n",
        "        print(f\"├── {f}\")\n",
        "else:\n",
        "    print(\"Cannot proceed without preprocessed data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3VECEh-KNiG",
        "outputId": "bd70544d-5f20-4f28-e879-2534a3fcc19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed: preprocessed_data.zip\n",
            "├── X_test.npy\n",
            "├── X_train.npy\n",
            "├── X_val.npy\n",
            "├── config.json\n",
            "├── y_test.npy\n",
            "├── y_test_cat.npy\n",
            "├── y_train.npy\n",
            "├── y_train_cat.npy\n",
            "├── y_val.npy\n",
            "├── y_val_cat.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment and Dependencies\n",
        "We utilize TensorFlow and Keras for building the neural network, along with NumPy and Pandas\n",
        "for data handling. Matplotlib and Seaborn are used for performance visualization"
      ],
      "metadata": {
        "id": "pbAmOWCCDSsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint,ReduceLROnPlateau,LearningRateScheduler)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H9-EXjiDa7f",
        "outputId": "9c2091cb-f388-4651-ed1e-9884537146cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pipeline\n",
        "The dataset consists of preprocessed MRI scans stored as NumPy arrays. We define paths for\n",
        "loading data and saving training artifacts."
      ],
      "metadata": {
        "id": "sK8aJrV4D01D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/preprocessed_data'\n",
        "OUTPUT_PATH = '/content/training_results'\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_PATH}/models', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_PATH}/histories', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_PATH}/plots', exist_ok=True)\n",
        "X_train = np.load(f'{DATA_PATH}/X_train.npy')\n",
        "X_val = np.load(f'{DATA_PATH}/X_val.npy')\n",
        "X_test = np.load(f'{DATA_PATH}/X_test.npy')\n",
        "y_train_cat = np.load(f'{DATA_PATH}/y_train_cat.npy')\n",
        "y_val_cat = np.load(f'{DATA_PATH}/y_val_cat.npy')\n",
        "y_test_cat = np.load(f'{DATA_PATH}/y_test_cat.npy')\n",
        "with open(f'{DATA_PATH}/config.json', 'r') as f:\n",
        "    config = json.load(f)"
      ],
      "metadata": {
        "id": "lQqnkGdUD7bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation Strategy\n",
        "\n",
        "To improve model generalization and mitigate overfitting, we implement a moderate augmentation strategy that includes rotations, shifts, and flips. Vertical flipping is deemed safe for MRI\n",
        "brain scans."
      ],
      "metadata": {
        "id": "ptPgafuqEEJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "gzZnMJ2tEKWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "\n",
        "The optimized CNN architecture consists of four convolutional blocks with increasing filter sizes\n",
        "(32, 64, 128, 256). Each block is followed by Batch Normalization and Dropout."
      ],
      "metadata": {
        "id": "fDGsTMNPEMto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_optimized_cnn(input_shape=(224, 224, 3), num_classes=4):\n",
        "    model = models.Sequential([\n",
        "        # Block 1\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "        # Block 2\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "        # Block 3\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.35),\n",
        "        # Block 4\n",
        "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.35),\n",
        "        # Dense classification head\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.55),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.55),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "s6bki0CXESOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_optimized_cnn(\n",
        "    input_shape=X_train.shape[1:],\n",
        "    num_classes=config['num_classes']\n",
        ")"
      ],
      "metadata": {
        "id": "z8x6izhJMAhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process\n",
        "\n",
        "The model is trained for 100 epochs using the Adam optimizer. We monitor validation accuracy\n",
        "to save the best weights and reduce the learning rate when the loss plateaus."
      ],
      "metadata": {
        "id": "im61zT55EYdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
        ")"
      ],
      "metadata": {
        "id": "HlSD6c4FEdcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(filepath=f'{OUTPUT_PATH}/models/best_model.h5', monitor='val_accuracy', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7)\n",
        "]"
      ],
      "metadata": {
        "id": "IeVFKAl-H2BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_datagen.flow(X_train, y_train_cat, batch_size=32),\n",
        "    epochs=100,\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEZDzykPH20m",
        "outputId": "fdcb57ea-faac-4a25-8311-aee6485f7e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step - accuracy: 0.5085 - loss: 1.4513 - precision: 0.5448 - recall: 0.4590"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 627ms/step - accuracy: 0.5090 - loss: 1.4496 - precision: 0.5453 - recall: 0.4594 - val_accuracy: 0.2835 - val_loss: 1.7722 - val_precision: 0.2923 - val_recall: 0.2660 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 423ms/step - accuracy: 0.6674 - loss: 0.8960 - precision: 0.7062 - recall: 0.6142 - val_accuracy: 0.2789 - val_loss: 3.0125 - val_precision: 0.2789 - val_recall: 0.2789 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 422ms/step - accuracy: 0.6916 - loss: 0.7933 - precision: 0.7347 - recall: 0.6363 - val_accuracy: 0.2789 - val_loss: 3.1869 - val_precision: 0.2789 - val_recall: 0.2789 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.7412 - loss: 0.6602 - precision: 0.7754 - recall: 0.6994"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 436ms/step - accuracy: 0.7412 - loss: 0.6601 - precision: 0.7755 - recall: 0.6995 - val_accuracy: 0.5951 - val_loss: 1.6923 - val_precision: 0.5995 - val_recall: 0.5904 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.7568 - loss: 0.6168 - precision: 0.7846 - recall: 0.7135"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 477ms/step - accuracy: 0.7569 - loss: 0.6166 - precision: 0.7847 - recall: 0.7136 - val_accuracy: 0.7713 - val_loss: 0.7189 - val_precision: 0.7724 - val_recall: 0.7643 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 419ms/step - accuracy: 0.7858 - loss: 0.5751 - precision: 0.8206 - recall: 0.7518 - val_accuracy: 0.6826 - val_loss: 1.2980 - val_precision: 0.6864 - val_recall: 0.6768 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 429ms/step - accuracy: 0.8263 - loss: 0.4709 - precision: 0.8443 - recall: 0.7951 - val_accuracy: 0.3314 - val_loss: 5.0027 - val_precision: 0.3310 - val_recall: 0.3302 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 425ms/step - accuracy: 0.8400 - loss: 0.4350 - precision: 0.8604 - recall: 0.8148 - val_accuracy: 0.7596 - val_loss: 0.7591 - val_precision: 0.7672 - val_recall: 0.7538 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.8362 - loss: 0.4493 - precision: 0.8524 - recall: 0.8108"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 483ms/step - accuracy: 0.8362 - loss: 0.4492 - precision: 0.8524 - recall: 0.8109 - val_accuracy: 0.8436 - val_loss: 0.4396 - val_precision: 0.8601 - val_recall: 0.8320 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 420ms/step - accuracy: 0.8406 - loss: 0.4191 - precision: 0.8601 - recall: 0.8250 - val_accuracy: 0.7550 - val_loss: 0.7010 - val_precision: 0.7703 - val_recall: 0.7316 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 427ms/step - accuracy: 0.8523 - loss: 0.3896 - precision: 0.8640 - recall: 0.8334 - val_accuracy: 0.7526 - val_loss: 0.7498 - val_precision: 0.7577 - val_recall: 0.7480 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 429ms/step - accuracy: 0.8473 - loss: 0.4074 - precision: 0.8629 - recall: 0.8301 - val_accuracy: 0.7316 - val_loss: 0.6804 - val_precision: 0.7745 - val_recall: 0.7013 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 423ms/step - accuracy: 0.8722 - loss: 0.3385 - precision: 0.8840 - recall: 0.8558 - val_accuracy: 0.6838 - val_loss: 0.9827 - val_precision: 0.7080 - val_recall: 0.6593 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 417ms/step - accuracy: 0.8767 - loss: 0.3484 - precision: 0.8860 - recall: 0.8651 - val_accuracy: 0.7223 - val_loss: 1.2028 - val_precision: 0.7252 - val_recall: 0.7176 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 425ms/step - accuracy: 0.8750 - loss: 0.3435 - precision: 0.8848 - recall: 0.8604 - val_accuracy: 0.3244 - val_loss: 2.0768 - val_precision: 0.3317 - val_recall: 0.3104 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 424ms/step - accuracy: 0.8746 - loss: 0.3360 - precision: 0.8867 - recall: 0.8583 - val_accuracy: 0.7001 - val_loss: 0.8516 - val_precision: 0.7327 - val_recall: 0.6686 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 417ms/step - accuracy: 0.8926 - loss: 0.2957 - precision: 0.9000 - recall: 0.8824 - val_accuracy: 0.8343 - val_loss: 0.5019 - val_precision: 0.8410 - val_recall: 0.8273 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 413ms/step - accuracy: 0.8946 - loss: 0.2789 - precision: 0.9041 - recall: 0.8836 - val_accuracy: 0.7923 - val_loss: 0.7601 - val_precision: 0.7965 - val_recall: 0.7900 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 429ms/step - accuracy: 0.9035 - loss: 0.2859 - precision: 0.9101 - recall: 0.8948 - val_accuracy: 0.7643 - val_loss: 0.7013 - val_precision: 0.7985 - val_recall: 0.7398 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 424ms/step - accuracy: 0.9057 - loss: 0.2519 - precision: 0.9158 - recall: 0.8967 - val_accuracy: 0.7678 - val_loss: 0.6172 - val_precision: 0.7939 - val_recall: 0.7550 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.8949 - loss: 0.2786 - precision: 0.9051 - recall: 0.8877"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 463ms/step - accuracy: 0.8949 - loss: 0.2785 - precision: 0.9052 - recall: 0.8878 - val_accuracy: 0.8926 - val_loss: 0.2802 - val_precision: 0.9068 - val_recall: 0.8856 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.9011 - loss: 0.2549 - precision: 0.9113 - recall: 0.8941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 463ms/step - accuracy: 0.9011 - loss: 0.2549 - precision: 0.9113 - recall: 0.8941 - val_accuracy: 0.8996 - val_loss: 0.2891 - val_precision: 0.9106 - val_recall: 0.8915 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 427ms/step - accuracy: 0.9271 - loss: 0.2054 - precision: 0.9333 - recall: 0.9202 - val_accuracy: 0.8355 - val_loss: 0.4888 - val_precision: 0.8556 - val_recall: 0.8296 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 426ms/step - accuracy: 0.9171 - loss: 0.2294 - precision: 0.9247 - recall: 0.9105 - val_accuracy: 0.5204 - val_loss: 1.5668 - val_precision: 0.5576 - val_recall: 0.4854 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 426ms/step - accuracy: 0.9069 - loss: 0.2362 - precision: 0.9148 - recall: 0.8988 - val_accuracy: 0.8740 - val_loss: 0.4000 - val_precision: 0.8868 - val_recall: 0.8681 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 418ms/step - accuracy: 0.9148 - loss: 0.2435 - precision: 0.9212 - recall: 0.9074 - val_accuracy: 0.8915 - val_loss: 0.3291 - val_precision: 0.9043 - val_recall: 0.8821 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 417ms/step - accuracy: 0.9170 - loss: 0.2311 - precision: 0.9240 - recall: 0.9131 - val_accuracy: 0.8938 - val_loss: 0.3798 - val_precision: 0.9026 - val_recall: 0.8868 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 424ms/step - accuracy: 0.9189 - loss: 0.2218 - precision: 0.9229 - recall: 0.9130 - val_accuracy: 0.8098 - val_loss: 0.5284 - val_precision: 0.8243 - val_recall: 0.7993 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.9288 - loss: 0.2008 - precision: 0.9340 - recall: 0.9268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 487ms/step - accuracy: 0.9288 - loss: 0.2007 - precision: 0.9341 - recall: 0.9268 - val_accuracy: 0.9417 - val_loss: 0.2001 - val_precision: 0.9448 - val_recall: 0.9393 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 421ms/step - accuracy: 0.9410 - loss: 0.1641 - precision: 0.9464 - recall: 0.9367 - val_accuracy: 0.9032 - val_loss: 0.2814 - val_precision: 0.9087 - val_recall: 0.8938 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 416ms/step - accuracy: 0.9338 - loss: 0.1781 - precision: 0.9373 - recall: 0.9278 - val_accuracy: 0.8343 - val_loss: 0.5308 - val_precision: 0.8430 - val_recall: 0.8273 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 412ms/step - accuracy: 0.9366 - loss: 0.1645 - precision: 0.9425 - recall: 0.9319 - val_accuracy: 0.8926 - val_loss: 0.3163 - val_precision: 0.8963 - val_recall: 0.8880 - learning_rate: 2.5000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 417ms/step - accuracy: 0.9318 - loss: 0.1848 - precision: 0.9375 - recall: 0.9298 - val_accuracy: 0.8915 - val_loss: 0.3798 - val_precision: 0.8941 - val_recall: 0.8868 - learning_rate: 2.5000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 417ms/step - accuracy: 0.9445 - loss: 0.1572 - precision: 0.9499 - recall: 0.9412 - val_accuracy: 0.8740 - val_loss: 0.4147 - val_precision: 0.8839 - val_recall: 0.8705 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 412ms/step - accuracy: 0.9251 - loss: 0.2036 - precision: 0.9289 - recall: 0.9215 - val_accuracy: 0.8600 - val_loss: 0.4394 - val_precision: 0.8678 - val_recall: 0.8576 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 416ms/step - accuracy: 0.9438 - loss: 0.1601 - precision: 0.9476 - recall: 0.9422 - val_accuracy: 0.9218 - val_loss: 0.2547 - val_precision: 0.9234 - val_recall: 0.9148 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 421ms/step - accuracy: 0.9393 - loss: 0.1713 - precision: 0.9459 - recall: 0.9355 - val_accuracy: 0.8915 - val_loss: 0.3737 - val_precision: 0.8952 - val_recall: 0.8868 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 417ms/step - accuracy: 0.9567 - loss: 0.1263 - precision: 0.9609 - recall: 0.9525 - val_accuracy: 0.9230 - val_loss: 0.2348 - val_precision: 0.9316 - val_recall: 0.9218 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 413ms/step - accuracy: 0.9408 - loss: 0.1603 - precision: 0.9445 - recall: 0.9390 - val_accuracy: 0.8868 - val_loss: 0.3496 - val_precision: 0.8967 - val_recall: 0.8810 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 430ms/step - accuracy: 0.9515 - loss: 0.1381 - precision: 0.9544 - recall: 0.9486 - val_accuracy: 0.9323 - val_loss: 0.2192 - val_precision: 0.9410 - val_recall: 0.9312 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 421ms/step - accuracy: 0.9537 - loss: 0.1342 - precision: 0.9569 - recall: 0.9502 - val_accuracy: 0.8821 - val_loss: 0.3423 - val_precision: 0.8923 - val_recall: 0.8798 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 421ms/step - accuracy: 0.9534 - loss: 0.1337 - precision: 0.9573 - recall: 0.9469 - val_accuracy: 0.8600 - val_loss: 0.4913 - val_precision: 0.8659 - val_recall: 0.8588 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 413ms/step - accuracy: 0.9519 - loss: 0.1385 - precision: 0.9560 - recall: 0.9489 - val_accuracy: 0.9347 - val_loss: 0.2346 - val_precision: 0.9367 - val_recall: 0.9323 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 434ms/step - accuracy: 0.9537 - loss: 0.1222 - precision: 0.9552 - recall: 0.9511 - val_accuracy: 0.9195 - val_loss: 0.2801 - val_precision: 0.9270 - val_recall: 0.9183 - learning_rate: 6.2500e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 431ms/step - accuracy: 0.9579 - loss: 0.1142 - precision: 0.9591 - recall: 0.9560 - val_accuracy: 0.9230 - val_loss: 0.2635 - val_precision: 0.9248 - val_recall: 0.9183 - learning_rate: 6.2500e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 423ms/step - accuracy: 0.9549 - loss: 0.1174 - precision: 0.9591 - recall: 0.9519 - val_accuracy: 0.9183 - val_loss: 0.2594 - val_precision: 0.9233 - val_recall: 0.9125 - learning_rate: 6.2500e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 418ms/step - accuracy: 0.9560 - loss: 0.1173 - precision: 0.9589 - recall: 0.9555 - val_accuracy: 0.9148 - val_loss: 0.2976 - val_precision: 0.9176 - val_recall: 0.9102 - learning_rate: 6.2500e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 416ms/step - accuracy: 0.9576 - loss: 0.1153 - precision: 0.9591 - recall: 0.9549 - val_accuracy: 0.9335 - val_loss: 0.2388 - val_precision: 0.9367 - val_recall: 0.9323 - learning_rate: 6.2500e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 433ms/step - accuracy: 0.9618 - loss: 0.1052 - precision: 0.9657 - recall: 0.9589 - val_accuracy: 0.9253 - val_loss: 0.2659 - val_precision: 0.9262 - val_recall: 0.9230 - learning_rate: 6.2500e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 432ms/step - accuracy: 0.9640 - loss: 0.1060 - precision: 0.9667 - recall: 0.9623 - val_accuracy: 0.8985 - val_loss: 0.3519 - val_precision: 0.9014 - val_recall: 0.8961 - learning_rate: 6.2500e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 422ms/step - accuracy: 0.9647 - loss: 0.1014 - precision: 0.9659 - recall: 0.9623 - val_accuracy: 0.9382 - val_loss: 0.2338 - val_precision: 0.9378 - val_recall: 0.9323 - learning_rate: 3.1250e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.9590 - loss: 0.1052 - precision: 0.9614 - recall: 0.9576"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 484ms/step - accuracy: 0.9590 - loss: 0.1052 - precision: 0.9614 - recall: 0.9576 - val_accuracy: 0.9428 - val_loss: 0.2148 - val_precision: 0.9449 - val_recall: 0.9405 - learning_rate: 3.1250e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 0.9656 - loss: 0.0969 - precision: 0.9682 - recall: 0.9651"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 441ms/step - accuracy: 0.9656 - loss: 0.0969 - precision: 0.9682 - recall: 0.9651 - val_accuracy: 0.9463 - val_loss: 0.1997 - val_precision: 0.9495 - val_recall: 0.9428 - learning_rate: 3.1250e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 426ms/step - accuracy: 0.9618 - loss: 0.1040 - precision: 0.9632 - recall: 0.9599 - val_accuracy: 0.9323 - val_loss: 0.2488 - val_precision: 0.9344 - val_recall: 0.9312 - learning_rate: 3.1250e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 435ms/step - accuracy: 0.9657 - loss: 0.1005 - precision: 0.9682 - recall: 0.9632 - val_accuracy: 0.9452 - val_loss: 0.1885 - val_precision: 0.9461 - val_recall: 0.9417 - learning_rate: 3.1250e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 443ms/step - accuracy: 0.9575 - loss: 0.1136 - precision: 0.9627 - recall: 0.9556 - val_accuracy: 0.9323 - val_loss: 0.2424 - val_precision: 0.9354 - val_recall: 0.9300 - learning_rate: 3.1250e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 422ms/step - accuracy: 0.9629 - loss: 0.1059 - precision: 0.9662 - recall: 0.9621 - val_accuracy: 0.9323 - val_loss: 0.2268 - val_precision: 0.9354 - val_recall: 0.9300 - learning_rate: 3.1250e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 420ms/step - accuracy: 0.9620 - loss: 0.1067 - precision: 0.9642 - recall: 0.9604 - val_accuracy: 0.9265 - val_loss: 0.2727 - val_precision: 0.9285 - val_recall: 0.9242 - learning_rate: 3.1250e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 429ms/step - accuracy: 0.9670 - loss: 0.0883 - precision: 0.9687 - recall: 0.9632 - val_accuracy: 0.9288 - val_loss: 0.2591 - val_precision: 0.9307 - val_recall: 0.9242 - learning_rate: 3.1250e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 429ms/step - accuracy: 0.9679 - loss: 0.0991 - precision: 0.9702 - recall: 0.9669 - val_accuracy: 0.9300 - val_loss: 0.2463 - val_precision: 0.9318 - val_recall: 0.9242 - learning_rate: 3.1250e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 427ms/step - accuracy: 0.9698 - loss: 0.0920 - precision: 0.9710 - recall: 0.9680 - val_accuracy: 0.9382 - val_loss: 0.2352 - val_precision: 0.9402 - val_recall: 0.9358 - learning_rate: 3.1250e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 424ms/step - accuracy: 0.9667 - loss: 0.0949 - precision: 0.9683 - recall: 0.9658 - val_accuracy: 0.9242 - val_loss: 0.2996 - val_precision: 0.9251 - val_recall: 0.9218 - learning_rate: 3.1250e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 417ms/step - accuracy: 0.9641 - loss: 0.1003 - precision: 0.9678 - recall: 0.9628 - val_accuracy: 0.9358 - val_loss: 0.2240 - val_precision: 0.9368 - val_recall: 0.9347 - learning_rate: 1.5625e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 429ms/step - accuracy: 0.9646 - loss: 0.0922 - precision: 0.9665 - recall: 0.9620 - val_accuracy: 0.9277 - val_loss: 0.2757 - val_precision: 0.9297 - val_recall: 0.9253 - learning_rate: 1.5625e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 426ms/step - accuracy: 0.9783 - loss: 0.0715 - precision: 0.9811 - recall: 0.9762 - val_accuracy: 0.9347 - val_loss: 0.2410 - val_precision: 0.9356 - val_recall: 0.9323 - learning_rate: 1.5625e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 425ms/step - accuracy: 0.9722 - loss: 0.0753 - precision: 0.9736 - recall: 0.9718 - val_accuracy: 0.9253 - val_loss: 0.2645 - val_precision: 0.9253 - val_recall: 0.9253 - learning_rate: 1.5625e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 428ms/step - accuracy: 0.9701 - loss: 0.0862 - precision: 0.9708 - recall: 0.9693 - val_accuracy: 0.9382 - val_loss: 0.2250 - val_precision: 0.9403 - val_recall: 0.9370 - learning_rate: 1.5625e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 417ms/step - accuracy: 0.9636 - loss: 0.1002 - precision: 0.9649 - recall: 0.9621 - val_accuracy: 0.9370 - val_loss: 0.2401 - val_precision: 0.9369 - val_recall: 0.9358 - learning_rate: 1.5625e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 430ms/step - accuracy: 0.9690 - loss: 0.0857 - precision: 0.9733 - recall: 0.9663 - val_accuracy: 0.9393 - val_loss: 0.2280 - val_precision: 0.9403 - val_recall: 0.9370 - learning_rate: 1.5625e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 429ms/step - accuracy: 0.9726 - loss: 0.0857 - precision: 0.9742 - recall: 0.9715 - val_accuracy: 0.9382 - val_loss: 0.2417 - val_precision: 0.9392 - val_recall: 0.9370 - learning_rate: 7.8125e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 428ms/step - accuracy: 0.9689 - loss: 0.0870 - precision: 0.9730 - recall: 0.9668 - val_accuracy: 0.9428 - val_loss: 0.2304 - val_precision: 0.9427 - val_recall: 0.9405 - learning_rate: 7.8125e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 429ms/step - accuracy: 0.9722 - loss: 0.0847 - precision: 0.9737 - recall: 0.9686 - val_accuracy: 0.9370 - val_loss: 0.2480 - val_precision: 0.9380 - val_recall: 0.9358 - learning_rate: 7.8125e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 418ms/step - accuracy: 0.9663 - loss: 0.0952 - precision: 0.9680 - recall: 0.9636 - val_accuracy: 0.9393 - val_loss: 0.2328 - val_precision: 0.9401 - val_recall: 0.9347 - learning_rate: 7.8125e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 439ms/step - accuracy: 0.9631 - loss: 0.0949 - precision: 0.9657 - recall: 0.9622 - val_accuracy: 0.9358 - val_loss: 0.2528 - val_precision: 0.9357 - val_recall: 0.9335 - learning_rate: 7.8125e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 426ms/step - accuracy: 0.9702 - loss: 0.0885 - precision: 0.9724 - recall: 0.9684 - val_accuracy: 0.9428 - val_loss: 0.2237 - val_precision: 0.9439 - val_recall: 0.9417 - learning_rate: 7.8125e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 416ms/step - accuracy: 0.9654 - loss: 0.0915 - precision: 0.9668 - recall: 0.9618 - val_accuracy: 0.9382 - val_loss: 0.2353 - val_precision: 0.9380 - val_recall: 0.9358 - learning_rate: 7.8125e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 422ms/step - accuracy: 0.9753 - loss: 0.0724 - precision: 0.9765 - recall: 0.9745 - val_accuracy: 0.9370 - val_loss: 0.2273 - val_precision: 0.9380 - val_recall: 0.9358 - learning_rate: 3.9063e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 425ms/step - accuracy: 0.9679 - loss: 0.0883 - precision: 0.9720 - recall: 0.9663 - val_accuracy: 0.9417 - val_loss: 0.2267 - val_precision: 0.9415 - val_recall: 0.9393 - learning_rate: 3.9063e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 425ms/step - accuracy: 0.9678 - loss: 0.0834 - precision: 0.9710 - recall: 0.9660 - val_accuracy: 0.9358 - val_loss: 0.2473 - val_precision: 0.9357 - val_recall: 0.9335 - learning_rate: 3.9063e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 416ms/step - accuracy: 0.9716 - loss: 0.0802 - precision: 0.9722 - recall: 0.9691 - val_accuracy: 0.9382 - val_loss: 0.2419 - val_precision: 0.9381 - val_recall: 0.9370 - learning_rate: 3.9063e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 418ms/step - accuracy: 0.9683 - loss: 0.0954 - precision: 0.9698 - recall: 0.9657 - val_accuracy: 0.9358 - val_loss: 0.2447 - val_precision: 0.9357 - val_recall: 0.9347 - learning_rate: 3.9063e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 422ms/step - accuracy: 0.9658 - loss: 0.0896 - precision: 0.9678 - recall: 0.9646 - val_accuracy: 0.9382 - val_loss: 0.2391 - val_precision: 0.9380 - val_recall: 0.9358 - learning_rate: 3.9063e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 422ms/step - accuracy: 0.9703 - loss: 0.0870 - precision: 0.9709 - recall: 0.9692 - val_accuracy: 0.9358 - val_loss: 0.2516 - val_precision: 0.9368 - val_recall: 0.9347 - learning_rate: 3.9063e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 422ms/step - accuracy: 0.9733 - loss: 0.0767 - precision: 0.9743 - recall: 0.9690 - val_accuracy: 0.9393 - val_loss: 0.2372 - val_precision: 0.9392 - val_recall: 0.9370 - learning_rate: 1.9531e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 416ms/step - accuracy: 0.9663 - loss: 0.0921 - precision: 0.9705 - recall: 0.9643 - val_accuracy: 0.9370 - val_loss: 0.2409 - val_precision: 0.9380 - val_recall: 0.9358 - learning_rate: 1.9531e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 429ms/step - accuracy: 0.9765 - loss: 0.0728 - precision: 0.9767 - recall: 0.9751 - val_accuracy: 0.9358 - val_loss: 0.2422 - val_precision: 0.9367 - val_recall: 0.9323 - learning_rate: 1.9531e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 420ms/step - accuracy: 0.9663 - loss: 0.0904 - precision: 0.9676 - recall: 0.9647 - val_accuracy: 0.9358 - val_loss: 0.2427 - val_precision: 0.9356 - val_recall: 0.9323 - learning_rate: 1.9531e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 422ms/step - accuracy: 0.9732 - loss: 0.0780 - precision: 0.9755 - recall: 0.9709 - val_accuracy: 0.9370 - val_loss: 0.2437 - val_precision: 0.9368 - val_recall: 0.9347 - learning_rate: 1.9531e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 418ms/step - accuracy: 0.9726 - loss: 0.0816 - precision: 0.9744 - recall: 0.9718 - val_accuracy: 0.9358 - val_loss: 0.2488 - val_precision: 0.9368 - val_recall: 0.9335 - learning_rate: 1.9531e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 428ms/step - accuracy: 0.9692 - loss: 0.0857 - precision: 0.9728 - recall: 0.9665 - val_accuracy: 0.9358 - val_loss: 0.2433 - val_precision: 0.9367 - val_recall: 0.9323 - learning_rate: 1.9531e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 430ms/step - accuracy: 0.9762 - loss: 0.0751 - precision: 0.9775 - recall: 0.9740 - val_accuracy: 0.9358 - val_loss: 0.2448 - val_precision: 0.9367 - val_recall: 0.9323 - learning_rate: 9.7656e-07\n",
            "Epoch 92/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 426ms/step - accuracy: 0.9721 - loss: 0.0816 - precision: 0.9737 - recall: 0.9706 - val_accuracy: 0.9358 - val_loss: 0.2443 - val_precision: 0.9357 - val_recall: 0.9335 - learning_rate: 9.7656e-07\n",
            "Epoch 93/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 422ms/step - accuracy: 0.9710 - loss: 0.0855 - precision: 0.9724 - recall: 0.9705 - val_accuracy: 0.9370 - val_loss: 0.2431 - val_precision: 0.9368 - val_recall: 0.9347 - learning_rate: 9.7656e-07\n",
            "Epoch 94/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 419ms/step - accuracy: 0.9722 - loss: 0.0798 - precision: 0.9736 - recall: 0.9715 - val_accuracy: 0.9370 - val_loss: 0.2393 - val_precision: 0.9368 - val_recall: 0.9347 - learning_rate: 9.7656e-07\n",
            "Epoch 95/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 428ms/step - accuracy: 0.9746 - loss: 0.0799 - precision: 0.9752 - recall: 0.9711 - val_accuracy: 0.9382 - val_loss: 0.2390 - val_precision: 0.9380 - val_recall: 0.9358 - learning_rate: 9.7656e-07\n",
            "Epoch 96/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 421ms/step - accuracy: 0.9648 - loss: 0.0912 - precision: 0.9655 - recall: 0.9630 - val_accuracy: 0.9382 - val_loss: 0.2410 - val_precision: 0.9379 - val_recall: 0.9347 - learning_rate: 9.7656e-07\n",
            "Epoch 97/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 436ms/step - accuracy: 0.9660 - loss: 0.0970 - precision: 0.9682 - recall: 0.9639 - val_accuracy: 0.9370 - val_loss: 0.2491 - val_precision: 0.9368 - val_recall: 0.9335 - learning_rate: 9.7656e-07\n",
            "Epoch 98/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 420ms/step - accuracy: 0.9735 - loss: 0.0856 - precision: 0.9749 - recall: 0.9721 - val_accuracy: 0.9370 - val_loss: 0.2446 - val_precision: 0.9368 - val_recall: 0.9347 - learning_rate: 4.8828e-07\n",
            "Epoch 99/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 425ms/step - accuracy: 0.9718 - loss: 0.0813 - precision: 0.9726 - recall: 0.9690 - val_accuracy: 0.9370 - val_loss: 0.2496 - val_precision: 0.9368 - val_recall: 0.9335 - learning_rate: 4.8828e-07\n",
            "Epoch 100/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 427ms/step - accuracy: 0.9701 - loss: 0.0889 - precision: 0.9714 - recall: 0.9685 - val_accuracy: 0.9370 - val_loss: 0.2448 - val_precision: 0.9368 - val_recall: 0.9335 - learning_rate: 4.8828e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'custom_cnn'"
      ],
      "metadata": {
        "id": "VD5A9In_pw95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_path = f'{OUTPUT_PATH}/histories/{MODEL_NAME}_history.npy'\n",
        "np.save(history_path, history.history)"
      ],
      "metadata": {
        "id": "LkvOHKYHpPAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_path = f'{OUTPUT_PATH}/models/{MODEL_NAME}_final.h5'\n",
        "model.save(final_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9w8vRVvps0w",
        "outputId": "21d076ed-0221-4031-8ddd-06e903ad9782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Time Augmentation (TTA)\n",
        "\n",
        "TTA is utilized during the inference phase. By generating 10 augmented versions of each test\n",
        "image and averaging the predictions, we significantly increase the robustness of the final classification."
      ],
      "metadata": {
        "id": "71ooRQa_EjTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model(f'{OUTPUT_PATH}/models/{MODEL_NAME}_final.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj8R9Ifyoi_9",
        "outputId": "af25262b-9c18-430a-c821-537d11d4aa6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_tta(model, X, n_augmentations=10):\n",
        "    predictions = []\n",
        "    preds = model.predict(X, verbose=0)\n",
        "    predictions.append(preds)\n",
        "    tta_gen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True\n",
        "    )\n",
        "    for i in range(n_augmentations):\n",
        "        aug_iterator = tta_gen.flow(X, batch_size=len(X), shuffle=False)\n",
        "        X_aug = next(iter(aug_iterator))\n",
        "        preds_aug = model.predict(X_aug, verbose=0)\n",
        "        predictions.append(preds_aug)\n",
        "    return np.mean(predictions, axis=0)\n",
        "\n",
        "test_preds_tta = predict_with_tta(best_model, X_test, n_augmentations=10)\n",
        "test_acc_tta = np.mean(np.argmax(test_preds_tta, axis=1) == np.argmax(y_test_cat, axis=1))\n",
        "\n",
        "print(f\"\\nTTA completed!\")\n",
        "\n",
        "# EVALUATION\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"EVALUATION\")\n",
        "\n",
        "# Validation\n",
        "val_results = best_model.evaluate(X_val, y_val_cat, verbose=0)\n",
        "print(f\"\\nValidation Results (Best Model):\")\n",
        "print(f\"Loss: {val_results[0]:.4f}\")\n",
        "print(f\"Accuracy: {val_results[1]*100:.2f}%\")\n",
        "print(f\"Precision: {val_results[2]:.4f}\")\n",
        "print(f\"Recall: {val_results[3]:.4f}\")\n",
        "\n",
        "# Test (standard)\n",
        "test_results = best_model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(f\"\\nTest Results (Standard):\")\n",
        "print(f\"Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Accuracy: {test_results[1]*100:.2f}%\")\n",
        "print(f\"Precision: {test_results[2]:.4f}\")\n",
        "print(f\"Recall: {test_results[3]:.4f}\")\n",
        "\n",
        "# Test (with TTA)\n",
        "print(f\"\\nTest Results (With TTA):\")\n",
        "print(f\"Accuracy: {test_acc_tta*100:.2f}%\")\n",
        "\n",
        "print(\"\\nSUMMARY:\")\n",
        "print(f\"Baseline Test Acc: 93.82%\")\n",
        "print(f\"Test Acc (Standard): {test_results[1]*100:.2f}%\")\n",
        "print(f\"Test Acc (TTA): {test_acc_tta*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZfVbTK3Eo_j",
        "outputId": "cf56d66e-ad5c-44ba-cde9-f1823574812f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TTA completed!\n",
            "\n",
            "\n",
            "EVALUATION\n",
            "\n",
            "Validation Results (Best Model):\n",
            "Loss: 0.2448\n",
            "Accuracy: 93.70%\n",
            "Precision: 0.9368\n",
            "Recall: 0.9335\n",
            "\n",
            "Test Results (Standard):\n",
            "Loss: 0.2143\n",
            "Accuracy: 93.14%\n",
            "Precision: 0.9353\n",
            "Recall: 0.9260\n",
            "\n",
            "Test Results (With TTA):\n",
            "Accuracy: 97.71%\n",
            "\n",
            "SUMMARY:\n",
            "Baseline Test Acc: 93.82%\n",
            "Test Acc (Standard): 93.14%\n",
            "Test Acc (TTA): 97.71%\n"
          ]
        }
      ]
    }
  ]
}
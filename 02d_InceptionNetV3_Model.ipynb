{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Brain Tumor MRI Classification Project"
      ],
      "metadata": {
        "id": "mL4j8GugDI8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Overview\n",
        "This project aims to classify brain tumors from MRI images into four distinct categories: Glioma, Meningioma, No Tumor, and Pituitary. In this first notebook, we establish the data pipeline, perform exploratory data analysis (EDA), and prepare the images for the deep learning training phase."
      ],
      "metadata": {
        "id": "iciabp01DNeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Preprocessed Data"
      ],
      "metadata": {
        "id": "8aFP2p1aKOyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "def extract_preprocessed_data():\n",
        "    zip_candidates = ['/content/preprocessed_data.zip', *glob.glob('/content/*preprocessed*.zip')]\n",
        "    zip_path = None\n",
        "    for candidate in zip_candidates:\n",
        "        if os.path.exists(candidate):\n",
        "            zip_path = candidate\n",
        "            break\n",
        "\n",
        "    if not zip_path:\n",
        "        print(\"preprocessed_data.zip not found in /content/\")\n",
        "        return False\n",
        "\n",
        "    if os.path.exists('/content/preprocessed_data') and os.path.exists('/content/preprocessed_data/config.json'):\n",
        "        required_files = [\n",
        "            'X_train.npy', 'X_val.npy', 'X_test.npy',\n",
        "            'y_train.npy', 'y_val.npy', 'y_test.npy',\n",
        "            'y_train_cat.npy', 'y_val_cat.npy', 'y_test_cat.npy',\n",
        "            'config.json'\n",
        "        ]\n",
        "        missing = [f for f in required_files if not os.path.exists(f'/content/preprocessed_data/{f}')]\n",
        "        if not missing:\n",
        "            print(\"preprocessed_data folder already exists\")\n",
        "            return True\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/')\n",
        "\n",
        "        print(f\"Extraction completed: {os.path.basename(zip_path)}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "if extract_preprocessed_data():\n",
        "    for f in sorted(os.listdir('/content/preprocessed_data')):\n",
        "        print(f\"├── {f}\")\n",
        "else:\n",
        "    print(\"Cannot proceed without preprocessed data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3VECEh-KNiG",
        "outputId": "c29d0c61-6a85-4245-d058-612f7e29cf1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed: preprocessed_data.zip\n",
            "├── X_test.npy\n",
            "├── X_train.npy\n",
            "├── X_val.npy\n",
            "├── config.json\n",
            "├── y_test.npy\n",
            "├── y_test_cat.npy\n",
            "├── y_train.npy\n",
            "├── y_train_cat.npy\n",
            "├── y_val.npy\n",
            "├── y_val_cat.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment and Dependencies\n",
        "We utilize TensorFlow and Keras for building the neural network, along with NumPy and Pandas\n",
        "for data handling. Matplotlib and Seaborn are used for performance visualization"
      ],
      "metadata": {
        "id": "pbAmOWCCDSsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint,ReduceLROnPlateau,LearningRateScheduler)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H9-EXjiDa7f",
        "outputId": "bf86944d-d1f8-4e9e-aed8-7abb88b34701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pipeline\n",
        "The dataset consists of preprocessed MRI scans stored as NumPy arrays. We define paths for\n",
        "loading data and saving training artifacts."
      ],
      "metadata": {
        "id": "sK8aJrV4D01D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/preprocessed_data'\n",
        "OUTPUT_PATH = '/content/training_results'\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_PATH}/models', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_PATH}/histories', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_PATH}/plots', exist_ok=True)\n",
        "X_train = np.load(f'{DATA_PATH}/X_train.npy')\n",
        "X_val = np.load(f'{DATA_PATH}/X_val.npy')\n",
        "X_test = np.load(f'{DATA_PATH}/X_test.npy')\n",
        "y_train_cat = np.load(f'{DATA_PATH}/y_train_cat.npy')\n",
        "y_val_cat = np.load(f'{DATA_PATH}/y_val_cat.npy')\n",
        "y_test_cat = np.load(f'{DATA_PATH}/y_test_cat.npy')\n",
        "with open(f'{DATA_PATH}/config.json', 'r') as f:\n",
        "    config = json.load(f)"
      ],
      "metadata": {
        "id": "lQqnkGdUD7bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation Strategy\n",
        "\n",
        "To improve model generalization and mitigate overfitting, we implement a moderate augmentation strategy that includes rotations, shifts, and flips. Vertical flipping is deemed safe for MRI\n",
        "brain scans."
      ],
      "metadata": {
        "id": "ptPgafuqEEJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "gzZnMJ2tEKWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "\n",
        "This time we use InceptionNetV3 as base model. we use ImageNet as weight for this transfer learning model. InceptionNetV3 is use as base model and we train the top layer of the model. Each block at the top layer is followed by Batch Normalization and Dropout."
      ],
      "metadata": {
        "id": "fDGsTMNPEMto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_inceptionv3(input_shape=(224, 224, 3), num_classes=4):\n",
        "    # Load InceptionV3 pre-trained\n",
        "    base_model = InceptionV3(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Freeze base model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Build model with InceptionV3\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.55),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.55),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "s6bki0CXESOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_inceptionv3(\n",
        "    input_shape=X_train.shape[1:],\n",
        "    num_classes=config['num_classes']\n",
        ")"
      ],
      "metadata": {
        "id": "z8x6izhJMAhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7e917d-7f19-465e-de3c-50e4608db59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process\n",
        "\n",
        "The model is trained for 100 epochs using the Adam optimizer. We monitor validation accuracy\n",
        "to save the best weights and reduce the learning rate when the loss plateaus."
      ],
      "metadata": {
        "id": "im61zT55EYdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
        ")"
      ],
      "metadata": {
        "id": "HlSD6c4FEdcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(filepath=f'{OUTPUT_PATH}/models/best_model.h5', monitor='val_accuracy', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7)\n",
        "]"
      ],
      "metadata": {
        "id": "IeVFKAl-H2BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_datagen.flow(X_train, y_train_cat, batch_size=32),\n",
        "    epochs=100,\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEZDzykPH20m",
        "outputId": "ba77b1f6-2ef2-4bf9-d810-d92855b2f5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.6259 - loss: 1.2031 - precision: 0.6403 - recall: 0.5930"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 551ms/step - accuracy: 0.6263 - loss: 1.2016 - precision: 0.6407 - recall: 0.5934 - val_accuracy: 0.7760 - val_loss: 0.6742 - val_precision: 0.7873 - val_recall: 0.7643 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.7722 - loss: 0.6587 - precision: 0.7902 - recall: 0.7543"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 388ms/step - accuracy: 0.7722 - loss: 0.6587 - precision: 0.7902 - recall: 0.7543 - val_accuracy: 0.8693 - val_loss: 0.3621 - val_precision: 0.8770 - val_recall: 0.8483 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 384ms/step - accuracy: 0.8008 - loss: 0.5497 - precision: 0.8242 - recall: 0.7798 - val_accuracy: 0.8565 - val_loss: 0.3472 - val_precision: 0.8764 - val_recall: 0.8436 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 389ms/step - accuracy: 0.8114 - loss: 0.4929 - precision: 0.8353 - recall: 0.7819 - val_accuracy: 0.8168 - val_loss: 0.3993 - val_precision: 0.8382 - val_recall: 0.7981 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8227 - loss: 0.4855 - precision: 0.8439 - recall: 0.8044"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 393ms/step - accuracy: 0.8227 - loss: 0.4855 - precision: 0.8439 - recall: 0.8044 - val_accuracy: 0.8845 - val_loss: 0.2949 - val_precision: 0.9039 - val_recall: 0.8670 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8438 - loss: 0.4283 - precision: 0.8596 - recall: 0.8256"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 390ms/step - accuracy: 0.8438 - loss: 0.4283 - precision: 0.8596 - recall: 0.8256 - val_accuracy: 0.9020 - val_loss: 0.2813 - val_precision: 0.9166 - val_recall: 0.8845 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 391ms/step - accuracy: 0.8433 - loss: 0.4371 - precision: 0.8600 - recall: 0.8234 - val_accuracy: 0.8763 - val_loss: 0.2988 - val_precision: 0.8967 - val_recall: 0.8611 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 379ms/step - accuracy: 0.8421 - loss: 0.4252 - precision: 0.8609 - recall: 0.8268 - val_accuracy: 0.8845 - val_loss: 0.2924 - val_precision: 0.8994 - val_recall: 0.8553 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 378ms/step - accuracy: 0.8437 - loss: 0.4231 - precision: 0.8658 - recall: 0.8249 - val_accuracy: 0.8938 - val_loss: 0.2739 - val_precision: 0.9065 - val_recall: 0.8821 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 387ms/step - accuracy: 0.8521 - loss: 0.3993 - precision: 0.8711 - recall: 0.8337 - val_accuracy: 0.8611 - val_loss: 0.3189 - val_precision: 0.8785 - val_recall: 0.8436 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 378ms/step - accuracy: 0.8582 - loss: 0.3724 - precision: 0.8746 - recall: 0.8418 - val_accuracy: 0.8588 - val_loss: 0.3317 - val_precision: 0.8811 - val_recall: 0.8471 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 381ms/step - accuracy: 0.8589 - loss: 0.3690 - precision: 0.8741 - recall: 0.8450 - val_accuracy: 0.9008 - val_loss: 0.2649 - val_precision: 0.9130 - val_recall: 0.8821 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 392ms/step - accuracy: 0.8534 - loss: 0.3956 - precision: 0.8693 - recall: 0.8335 - val_accuracy: 0.8471 - val_loss: 0.3619 - val_precision: 0.8634 - val_recall: 0.8331 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 381ms/step - accuracy: 0.8592 - loss: 0.3647 - precision: 0.8745 - recall: 0.8426 - val_accuracy: 0.8985 - val_loss: 0.2605 - val_precision: 0.9138 - val_recall: 0.8786 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 389ms/step - accuracy: 0.8556 - loss: 0.3755 - precision: 0.8716 - recall: 0.8385 - val_accuracy: 0.8985 - val_loss: 0.2601 - val_precision: 0.9114 - val_recall: 0.8880 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 380ms/step - accuracy: 0.8636 - loss: 0.3662 - precision: 0.8815 - recall: 0.8469 - val_accuracy: 0.8996 - val_loss: 0.2595 - val_precision: 0.9147 - val_recall: 0.8880 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 379ms/step - accuracy: 0.8541 - loss: 0.3714 - precision: 0.8732 - recall: 0.8365 - val_accuracy: 0.8810 - val_loss: 0.2716 - val_precision: 0.9058 - val_recall: 0.8635 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8796 - loss: 0.3432 - precision: 0.8942 - recall: 0.8588"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 385ms/step - accuracy: 0.8795 - loss: 0.3433 - precision: 0.8942 - recall: 0.8587 - val_accuracy: 0.9160 - val_loss: 0.2353 - val_precision: 0.9228 - val_recall: 0.9067 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 378ms/step - accuracy: 0.8690 - loss: 0.3518 - precision: 0.8846 - recall: 0.8527 - val_accuracy: 0.9125 - val_loss: 0.2548 - val_precision: 0.9205 - val_recall: 0.8915 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 381ms/step - accuracy: 0.8712 - loss: 0.3474 - precision: 0.8882 - recall: 0.8556 - val_accuracy: 0.9148 - val_loss: 0.2325 - val_precision: 0.9211 - val_recall: 0.8996 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 387ms/step - accuracy: 0.8620 - loss: 0.3577 - precision: 0.8804 - recall: 0.8492 - val_accuracy: 0.9055 - val_loss: 0.2366 - val_precision: 0.9166 - val_recall: 0.8973 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 382ms/step - accuracy: 0.8651 - loss: 0.3576 - precision: 0.8817 - recall: 0.8472 - val_accuracy: 0.8973 - val_loss: 0.2719 - val_precision: 0.9054 - val_recall: 0.8821 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 389ms/step - accuracy: 0.8722 - loss: 0.3431 - precision: 0.8847 - recall: 0.8548 - val_accuracy: 0.9055 - val_loss: 0.2570 - val_precision: 0.9137 - val_recall: 0.8891 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 378ms/step - accuracy: 0.8789 - loss: 0.3235 - precision: 0.8936 - recall: 0.8645 - val_accuracy: 0.9102 - val_loss: 0.2481 - val_precision: 0.9179 - val_recall: 0.8996 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 380ms/step - accuracy: 0.8743 - loss: 0.3448 - precision: 0.8871 - recall: 0.8575 - val_accuracy: 0.8996 - val_loss: 0.2397 - val_precision: 0.9171 - val_recall: 0.8903 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 385ms/step - accuracy: 0.8719 - loss: 0.3284 - precision: 0.8884 - recall: 0.8540 - val_accuracy: 0.9008 - val_loss: 0.2555 - val_precision: 0.9160 - val_recall: 0.8903 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 378ms/step - accuracy: 0.8773 - loss: 0.3298 - precision: 0.8929 - recall: 0.8628 - val_accuracy: 0.9090 - val_loss: 0.2421 - val_precision: 0.9211 - val_recall: 0.8985 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 383ms/step - accuracy: 0.8694 - loss: 0.3384 - precision: 0.8839 - recall: 0.8526 - val_accuracy: 0.9125 - val_loss: 0.2304 - val_precision: 0.9272 - val_recall: 0.9067 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 382ms/step - accuracy: 0.8880 - loss: 0.3000 - precision: 0.9006 - recall: 0.8748 - val_accuracy: 0.9008 - val_loss: 0.2467 - val_precision: 0.9119 - val_recall: 0.8938 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 383ms/step - accuracy: 0.8821 - loss: 0.3161 - precision: 0.8985 - recall: 0.8667 - val_accuracy: 0.9090 - val_loss: 0.2238 - val_precision: 0.9202 - val_recall: 0.9020 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8806 - loss: 0.3087 - precision: 0.8945 - recall: 0.8666"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 393ms/step - accuracy: 0.8806 - loss: 0.3087 - precision: 0.8945 - recall: 0.8666 - val_accuracy: 0.9172 - val_loss: 0.2223 - val_precision: 0.9284 - val_recall: 0.9078 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8788 - loss: 0.3191 - precision: 0.8892 - recall: 0.8631"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 385ms/step - accuracy: 0.8789 - loss: 0.3190 - precision: 0.8892 - recall: 0.8632 - val_accuracy: 0.9183 - val_loss: 0.2214 - val_precision: 0.9230 - val_recall: 0.9090 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 379ms/step - accuracy: 0.8753 - loss: 0.3230 - precision: 0.8920 - recall: 0.8652 - val_accuracy: 0.9067 - val_loss: 0.2472 - val_precision: 0.9133 - val_recall: 0.8973 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 386ms/step - accuracy: 0.8883 - loss: 0.3031 - precision: 0.9021 - recall: 0.8737 - val_accuracy: 0.9102 - val_loss: 0.2181 - val_precision: 0.9222 - val_recall: 0.8985 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 378ms/step - accuracy: 0.8836 - loss: 0.3153 - precision: 0.8971 - recall: 0.8699 - val_accuracy: 0.8985 - val_loss: 0.2367 - val_precision: 0.9150 - val_recall: 0.8915 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 386ms/step - accuracy: 0.8914 - loss: 0.2842 - precision: 0.9028 - recall: 0.8816 - val_accuracy: 0.9172 - val_loss: 0.2163 - val_precision: 0.9236 - val_recall: 0.9032 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 380ms/step - accuracy: 0.8925 - loss: 0.2975 - precision: 0.9055 - recall: 0.8816 - val_accuracy: 0.9043 - val_loss: 0.2383 - val_precision: 0.9128 - val_recall: 0.8915 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 379ms/step - accuracy: 0.8943 - loss: 0.2879 - precision: 0.9076 - recall: 0.8825 - val_accuracy: 0.9078 - val_loss: 0.2314 - val_precision: 0.9186 - val_recall: 0.8950 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 391ms/step - accuracy: 0.8851 - loss: 0.3170 - precision: 0.8986 - recall: 0.8730 - val_accuracy: 0.9090 - val_loss: 0.2320 - val_precision: 0.9181 - val_recall: 0.9032 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 389ms/step - accuracy: 0.8876 - loss: 0.2894 - precision: 0.9027 - recall: 0.8762 - val_accuracy: 0.9020 - val_loss: 0.2464 - val_precision: 0.9222 - val_recall: 0.8856 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 382ms/step - accuracy: 0.8950 - loss: 0.2861 - precision: 0.9097 - recall: 0.8849 - val_accuracy: 0.8996 - val_loss: 0.2551 - val_precision: 0.9060 - val_recall: 0.8880 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 383ms/step - accuracy: 0.8995 - loss: 0.2646 - precision: 0.9082 - recall: 0.8867 - val_accuracy: 0.9183 - val_loss: 0.2245 - val_precision: 0.9254 - val_recall: 0.8973 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8875 - loss: 0.2890 - precision: 0.8984 - recall: 0.8752"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 385ms/step - accuracy: 0.8875 - loss: 0.2891 - precision: 0.8984 - recall: 0.8751 - val_accuracy: 0.9218 - val_loss: 0.2158 - val_precision: 0.9286 - val_recall: 0.9102 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 381ms/step - accuracy: 0.8951 - loss: 0.2902 - precision: 0.9079 - recall: 0.8832 - val_accuracy: 0.9183 - val_loss: 0.2230 - val_precision: 0.9217 - val_recall: 0.9067 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8887 - loss: 0.2943 - precision: 0.9029 - recall: 0.8763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 383ms/step - accuracy: 0.8887 - loss: 0.2943 - precision: 0.9029 - recall: 0.8763 - val_accuracy: 0.9230 - val_loss: 0.2091 - val_precision: 0.9291 - val_recall: 0.9172 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 380ms/step - accuracy: 0.8934 - loss: 0.2897 - precision: 0.9063 - recall: 0.8825 - val_accuracy: 0.9067 - val_loss: 0.2321 - val_precision: 0.9190 - val_recall: 0.8996 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 389ms/step - accuracy: 0.8915 - loss: 0.2781 - precision: 0.8993 - recall: 0.8791 - val_accuracy: 0.9090 - val_loss: 0.2387 - val_precision: 0.9180 - val_recall: 0.9008 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 386ms/step - accuracy: 0.8882 - loss: 0.2924 - precision: 0.8989 - recall: 0.8781 - val_accuracy: 0.9160 - val_loss: 0.2143 - val_precision: 0.9252 - val_recall: 0.9090 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 380ms/step - accuracy: 0.8917 - loss: 0.2822 - precision: 0.9051 - recall: 0.8821 - val_accuracy: 0.9008 - val_loss: 0.2599 - val_precision: 0.9088 - val_recall: 0.8950 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 383ms/step - accuracy: 0.8916 - loss: 0.3005 - precision: 0.9002 - recall: 0.8808 - val_accuracy: 0.9183 - val_loss: 0.2103 - val_precision: 0.9243 - val_recall: 0.9113 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 381ms/step - accuracy: 0.8968 - loss: 0.2876 - precision: 0.9075 - recall: 0.8861 - val_accuracy: 0.9230 - val_loss: 0.1960 - val_precision: 0.9325 - val_recall: 0.9183 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 387ms/step - accuracy: 0.8929 - loss: 0.2841 - precision: 0.8993 - recall: 0.8867 - val_accuracy: 0.8915 - val_loss: 0.2619 - val_precision: 0.8986 - val_recall: 0.8786 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.8951 - loss: 0.2880 - precision: 0.9064 - recall: 0.8853"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 383ms/step - accuracy: 0.8950 - loss: 0.2880 - precision: 0.9064 - recall: 0.8853 - val_accuracy: 0.9347 - val_loss: 0.1917 - val_precision: 0.9433 - val_recall: 0.9312 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 380ms/step - accuracy: 0.8968 - loss: 0.2769 - precision: 0.9067 - recall: 0.8865 - val_accuracy: 0.8985 - val_loss: 0.2384 - val_precision: 0.9147 - val_recall: 0.8880 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 394ms/step - accuracy: 0.8936 - loss: 0.2772 - precision: 0.9050 - recall: 0.8798 - val_accuracy: 0.9102 - val_loss: 0.2166 - val_precision: 0.9215 - val_recall: 0.9043 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 377ms/step - accuracy: 0.8925 - loss: 0.2867 - precision: 0.9057 - recall: 0.8816 - val_accuracy: 0.9277 - val_loss: 0.1876 - val_precision: 0.9348 - val_recall: 0.9195 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 384ms/step - accuracy: 0.8944 - loss: 0.2822 - precision: 0.9063 - recall: 0.8846 - val_accuracy: 0.9032 - val_loss: 0.2227 - val_precision: 0.9142 - val_recall: 0.8950 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 386ms/step - accuracy: 0.8902 - loss: 0.2913 - precision: 0.9004 - recall: 0.8748 - val_accuracy: 0.9300 - val_loss: 0.1946 - val_precision: 0.9403 - val_recall: 0.9183 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 378ms/step - accuracy: 0.8901 - loss: 0.2773 - precision: 0.9020 - recall: 0.8784 - val_accuracy: 0.9125 - val_loss: 0.2200 - val_precision: 0.9193 - val_recall: 0.9043 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 386ms/step - accuracy: 0.8940 - loss: 0.2756 - precision: 0.9032 - recall: 0.8840 - val_accuracy: 0.9253 - val_loss: 0.1921 - val_precision: 0.9334 - val_recall: 0.9160 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 378ms/step - accuracy: 0.8962 - loss: 0.2775 - precision: 0.9069 - recall: 0.8886 - val_accuracy: 0.9265 - val_loss: 0.2012 - val_precision: 0.9338 - val_recall: 0.9218 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 380ms/step - accuracy: 0.8955 - loss: 0.2885 - precision: 0.9041 - recall: 0.8838 - val_accuracy: 0.9230 - val_loss: 0.2018 - val_precision: 0.9290 - val_recall: 0.9160 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 390ms/step - accuracy: 0.8872 - loss: 0.2859 - precision: 0.8975 - recall: 0.8764 - val_accuracy: 0.9253 - val_loss: 0.1840 - val_precision: 0.9336 - val_recall: 0.9195 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 382ms/step - accuracy: 0.8987 - loss: 0.2694 - precision: 0.9078 - recall: 0.8904 - val_accuracy: 0.9113 - val_loss: 0.2268 - val_precision: 0.9219 - val_recall: 0.8950 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 387ms/step - accuracy: 0.8809 - loss: 0.3024 - precision: 0.8912 - recall: 0.8659 - val_accuracy: 0.9067 - val_loss: 0.2510 - val_precision: 0.9124 - val_recall: 0.8996 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 389ms/step - accuracy: 0.8943 - loss: 0.2710 - precision: 0.9071 - recall: 0.8826 - val_accuracy: 0.9172 - val_loss: 0.2063 - val_precision: 0.9283 - val_recall: 0.9067 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 390ms/step - accuracy: 0.8914 - loss: 0.2882 - precision: 0.9016 - recall: 0.8776 - val_accuracy: 0.9102 - val_loss: 0.2253 - val_precision: 0.9173 - val_recall: 0.9055 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 397ms/step - accuracy: 0.8934 - loss: 0.2848 - precision: 0.9025 - recall: 0.8822 - val_accuracy: 0.9300 - val_loss: 0.2066 - val_precision: 0.9371 - val_recall: 0.9218 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 389ms/step - accuracy: 0.9032 - loss: 0.2461 - precision: 0.9109 - recall: 0.8932 - val_accuracy: 0.9032 - val_loss: 0.2249 - val_precision: 0.9123 - val_recall: 0.8985 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 396ms/step - accuracy: 0.8904 - loss: 0.2920 - precision: 0.9038 - recall: 0.8809 - val_accuracy: 0.9207 - val_loss: 0.2050 - val_precision: 0.9233 - val_recall: 0.9125 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 392ms/step - accuracy: 0.8966 - loss: 0.2844 - precision: 0.9072 - recall: 0.8847 - val_accuracy: 0.9265 - val_loss: 0.1930 - val_precision: 0.9313 - val_recall: 0.9172 - learning_rate: 2.5000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 403ms/step - accuracy: 0.8955 - loss: 0.2671 - precision: 0.9019 - recall: 0.8838 - val_accuracy: 0.9300 - val_loss: 0.1927 - val_precision: 0.9359 - val_recall: 0.9207 - learning_rate: 2.5000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 392ms/step - accuracy: 0.9087 - loss: 0.2592 - precision: 0.9161 - recall: 0.8990 - val_accuracy: 0.9242 - val_loss: 0.2084 - val_precision: 0.9311 - val_recall: 0.9148 - learning_rate: 2.5000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 393ms/step - accuracy: 0.8995 - loss: 0.2667 - precision: 0.9093 - recall: 0.8884 - val_accuracy: 0.9230 - val_loss: 0.1941 - val_precision: 0.9269 - val_recall: 0.9172 - learning_rate: 2.5000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 381ms/step - accuracy: 0.9074 - loss: 0.2600 - precision: 0.9134 - recall: 0.8937 - val_accuracy: 0.9067 - val_loss: 0.2327 - val_precision: 0.9107 - val_recall: 0.8926 - learning_rate: 2.5000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 379ms/step - accuracy: 0.9055 - loss: 0.2522 - precision: 0.9133 - recall: 0.8969 - val_accuracy: 0.9300 - val_loss: 0.1933 - val_precision: 0.9338 - val_recall: 0.9218 - learning_rate: 2.5000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 390ms/step - accuracy: 0.9037 - loss: 0.2727 - precision: 0.9102 - recall: 0.8942 - val_accuracy: 0.9300 - val_loss: 0.2024 - val_precision: 0.9351 - val_recall: 0.9242 - learning_rate: 2.5000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 381ms/step - accuracy: 0.9104 - loss: 0.2486 - precision: 0.9188 - recall: 0.8974 - val_accuracy: 0.9335 - val_loss: 0.1978 - val_precision: 0.9420 - val_recall: 0.9288 - learning_rate: 1.2500e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 381ms/step - accuracy: 0.9106 - loss: 0.2511 - precision: 0.9189 - recall: 0.9044 - val_accuracy: 0.9335 - val_loss: 0.1919 - val_precision: 0.9383 - val_recall: 0.9230 - learning_rate: 1.2500e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 393ms/step - accuracy: 0.9103 - loss: 0.2508 - precision: 0.9174 - recall: 0.8979 - val_accuracy: 0.9335 - val_loss: 0.1934 - val_precision: 0.9409 - val_recall: 0.9288 - learning_rate: 1.2500e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 381ms/step - accuracy: 0.9123 - loss: 0.2495 - precision: 0.9228 - recall: 0.9001 - val_accuracy: 0.9265 - val_loss: 0.1982 - val_precision: 0.9327 - val_recall: 0.9218 - learning_rate: 1.2500e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 390ms/step - accuracy: 0.9051 - loss: 0.2587 - precision: 0.9170 - recall: 0.8953 - val_accuracy: 0.9277 - val_loss: 0.1988 - val_precision: 0.9326 - val_recall: 0.9207 - learning_rate: 1.2500e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 389ms/step - accuracy: 0.9154 - loss: 0.2318 - precision: 0.9239 - recall: 0.9059 - val_accuracy: 0.9323 - val_loss: 0.1957 - val_precision: 0.9372 - val_recall: 0.9230 - learning_rate: 1.2500e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 387ms/step - accuracy: 0.9074 - loss: 0.2440 - precision: 0.9159 - recall: 0.8990 - val_accuracy: 0.9277 - val_loss: 0.1991 - val_precision: 0.9294 - val_recall: 0.9218 - learning_rate: 1.2500e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 390ms/step - accuracy: 0.9041 - loss: 0.2527 - precision: 0.9120 - recall: 0.8954 - val_accuracy: 0.9277 - val_loss: 0.1912 - val_precision: 0.9317 - val_recall: 0.9230 - learning_rate: 6.2500e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 385ms/step - accuracy: 0.9087 - loss: 0.2499 - precision: 0.9187 - recall: 0.9033 - val_accuracy: 0.9288 - val_loss: 0.1904 - val_precision: 0.9338 - val_recall: 0.9218 - learning_rate: 6.2500e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 395ms/step - accuracy: 0.9129 - loss: 0.2446 - precision: 0.9177 - recall: 0.9048 - val_accuracy: 0.9288 - val_loss: 0.1965 - val_precision: 0.9361 - val_recall: 0.9230 - learning_rate: 6.2500e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 391ms/step - accuracy: 0.9171 - loss: 0.2230 - precision: 0.9256 - recall: 0.9082 - val_accuracy: 0.9300 - val_loss: 0.1973 - val_precision: 0.9363 - val_recall: 0.9265 - learning_rate: 6.2500e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 384ms/step - accuracy: 0.9078 - loss: 0.2501 - precision: 0.9169 - recall: 0.8994 - val_accuracy: 0.9288 - val_loss: 0.1905 - val_precision: 0.9337 - val_recall: 0.9207 - learning_rate: 6.2500e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 387ms/step - accuracy: 0.9135 - loss: 0.2436 - precision: 0.9199 - recall: 0.9064 - val_accuracy: 0.9300 - val_loss: 0.1899 - val_precision: 0.9351 - val_recall: 0.9253 - learning_rate: 6.2500e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 392ms/step - accuracy: 0.9170 - loss: 0.2275 - precision: 0.9248 - recall: 0.9104 - val_accuracy: 0.9300 - val_loss: 0.1906 - val_precision: 0.9352 - val_recall: 0.9265 - learning_rate: 6.2500e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 386ms/step - accuracy: 0.9120 - loss: 0.2152 - precision: 0.9198 - recall: 0.9044 - val_accuracy: 0.9288 - val_loss: 0.1921 - val_precision: 0.9373 - val_recall: 0.9242 - learning_rate: 3.1250e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 388ms/step - accuracy: 0.9090 - loss: 0.2404 - precision: 0.9185 - recall: 0.8996 - val_accuracy: 0.9277 - val_loss: 0.1919 - val_precision: 0.9383 - val_recall: 0.9230 - learning_rate: 3.1250e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 390ms/step - accuracy: 0.9105 - loss: 0.2483 - precision: 0.9192 - recall: 0.9027 - val_accuracy: 0.9300 - val_loss: 0.1870 - val_precision: 0.9383 - val_recall: 0.9230 - learning_rate: 3.1250e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 392ms/step - accuracy: 0.9096 - loss: 0.2283 - precision: 0.9192 - recall: 0.9035 - val_accuracy: 0.9300 - val_loss: 0.1903 - val_precision: 0.9362 - val_recall: 0.9242 - learning_rate: 3.1250e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 385ms/step - accuracy: 0.9110 - loss: 0.2460 - precision: 0.9180 - recall: 0.9013 - val_accuracy: 0.9288 - val_loss: 0.1954 - val_precision: 0.9317 - val_recall: 0.9230 - learning_rate: 3.1250e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 386ms/step - accuracy: 0.9070 - loss: 0.2604 - precision: 0.9147 - recall: 0.8959 - val_accuracy: 0.9300 - val_loss: 0.1931 - val_precision: 0.9361 - val_recall: 0.9230 - learning_rate: 3.1250e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 388ms/step - accuracy: 0.9107 - loss: 0.2348 - precision: 0.9183 - recall: 0.9006 - val_accuracy: 0.9277 - val_loss: 0.1935 - val_precision: 0.9349 - val_recall: 0.9218 - learning_rate: 3.1250e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 399ms/step - accuracy: 0.9063 - loss: 0.2487 - precision: 0.9165 - recall: 0.9009 - val_accuracy: 0.9288 - val_loss: 0.1941 - val_precision: 0.9328 - val_recall: 0.9230 - learning_rate: 1.5625e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 383ms/step - accuracy: 0.9112 - loss: 0.2436 - precision: 0.9208 - recall: 0.9047 - val_accuracy: 0.9288 - val_loss: 0.1966 - val_precision: 0.9339 - val_recall: 0.9230 - learning_rate: 1.5625e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'inceptionv3'"
      ],
      "metadata": {
        "id": "VD5A9In_pw95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_path = f'{OUTPUT_PATH}/histories/{MODEL_NAME}_history.npy'\n",
        "np.save(history_path, history.history)"
      ],
      "metadata": {
        "id": "LkvOHKYHpPAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_path = f'{OUTPUT_PATH}/models/{MODEL_NAME}_final.h5'\n",
        "model.save(final_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9w8vRVvps0w",
        "outputId": "042c6620-f676-45f8-ea08-beadd5d90369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model(f'{OUTPUT_PATH}/models/{MODEL_NAME}_final.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj8R9Ifyoi_9",
        "outputId": "b8411df9-3a22-4364-e397-c5c0bee23d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Time Augmentation (TTA)\n",
        "\n",
        "TTA is utilized during the inference phase. By generating 10 augmented versions of each test\n",
        "image and averaging the predictions, we significantly increase the robustness of the final classification."
      ],
      "metadata": {
        "id": "71ooRQa_EjTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_tta(model, X, n_augmentations=10):\n",
        "    predictions = []\n",
        "    preds = model.predict(X, verbose=0)\n",
        "    predictions.append(preds)\n",
        "    tta_gen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True\n",
        "    )\n",
        "    for i in range(n_augmentations):\n",
        "        aug_iterator = tta_gen.flow(X, batch_size=len(X), shuffle=False)\n",
        "        X_aug = next(iter(aug_iterator))\n",
        "        preds_aug = model.predict(X_aug, verbose=0)\n",
        "        predictions.append(preds_aug)\n",
        "    return np.mean(predictions, axis=0)\n",
        "\n",
        "test_preds_tta = predict_with_tta(best_model, X_test, n_augmentations=10)\n",
        "test_acc_tta = np.mean(np.argmax(test_preds_tta, axis=1) == np.argmax(y_test_cat, axis=1))\n",
        "\n",
        "print(f\"\\nTTA completed!\")\n",
        "\n",
        "# EVALUATION\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"EVALUATION\")\n",
        "\n",
        "# Validation\n",
        "val_results = best_model.evaluate(X_val, y_val_cat, verbose=0)\n",
        "print(f\"\\nValidation Results (Best Model):\")\n",
        "print(f\"Loss: {val_results[0]:.4f}\")\n",
        "print(f\"Accuracy: {val_results[1]*100:.2f}%\")\n",
        "print(f\"Precision: {val_results[2]:.4f}\")\n",
        "print(f\"Recall: {val_results[3]:.4f}\")\n",
        "\n",
        "# Test (standard)\n",
        "test_results = best_model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(f\"\\nTest Results (Standard):\")\n",
        "print(f\"Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Accuracy: {test_results[1]*100:.2f}%\")\n",
        "print(f\"Precision: {test_results[2]:.4f}\")\n",
        "print(f\"Recall: {test_results[3]:.4f}\")\n",
        "\n",
        "# Test (with TTA)\n",
        "print(f\"\\nTest Results (With TTA):\")\n",
        "print(f\"Accuracy: {test_acc_tta*100:.2f}%\")\n",
        "\n",
        "print(\"\\nSUMMARY:\")\n",
        "print(f\"Baseline Test Acc: 93.82%\")\n",
        "print(f\"Test Acc (Standard): {test_results[1]*100:.2f}%\")\n",
        "print(f\"Test Acc (TTA): {test_acc_tta*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZfVbTK3Eo_j",
        "outputId": "52b9f1e8-4d99-4194-d364-7b68466c8628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TTA completed!\n",
            "\n",
            "\n",
            "EVALUATION\n",
            "\n",
            "Validation Results (Best Model):\n",
            "Loss: 0.1966\n",
            "Accuracy: 92.88%\n",
            "Precision: 0.9339\n",
            "Recall: 0.9230\n",
            "\n",
            "Test Results (Standard):\n",
            "Loss: 0.2196\n",
            "Accuracy: 91.30%\n",
            "Precision: 0.9194\n",
            "Recall: 0.9047\n",
            "\n",
            "Test Results (With TTA):\n",
            "Accuracy: 93.67%\n",
            "\n",
            "SUMMARY:\n",
            "Baseline Test Acc: 93.82%\n",
            "Test Acc (Standard): 91.30%\n",
            "Test Acc (TTA): 93.67%\n"
          ]
        }
      ]
    }
  ]
}